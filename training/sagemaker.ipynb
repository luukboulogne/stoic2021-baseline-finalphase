{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "48171738-06dc-4d0b-8aa5-2c5b4912c832",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from sagemaker.pytorch import PyTorch\n",
    "from sagemaker import get_execution_role"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c79494e5-f2b4-4e41-9e8e-4c791c15630e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set location of dataset, and locations to write preprocessed data and artifact\n",
    "\n",
    "dataset_location = \"s3://rumc-stoic-p-sagemaker-luuk-boulogne/stoic21/test/dataset/\"\n",
    "preprocessed_location = \"s3://rumc-stoic-p-sagemaker-luuk-boulogne/stoic21/test/preprocessed/\"\n",
    "artifact_location = \"s3://rumc-stoic-p-sagemaker-luuk-boulogne/stoic21/test/artifact/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "07f48064-b45c-4d1b-a14e-ba6eeca3a7ca",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-02-02 12:54:24 Starting - Starting the training job...\n",
      "2023-02-02 12:54:50 Starting - Preparing the instances for trainingProfilerReport-1675342464: InProgress\n",
      "......\n",
      "2023-02-02 12:55:50 Downloading - Downloading input data...\n",
      "2023-02-02 12:56:19 Training - Downloading the training image......\n",
      "2023-02-02 12:57:10 Training - Training image download completed. Training in progress.\u001b[34mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[34mbash: no job control in this shell\u001b[0m\n",
      "\u001b[34m2023-02-02 12:57:11,294 sagemaker-training-toolkit INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
      "\u001b[34m2023-02-02 12:57:11,296 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2023-02-02 12:57:11,299 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2023-02-02 12:57:11,310 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n",
      "\u001b[34m2023-02-02 12:57:11,312 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[34m2023-02-02 12:57:12,214 sagemaker-training-toolkit INFO     Installing dependencies from requirements.txt:\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python3.8 -m pip install -r requirements.txt\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: scikit-learn>=0.20.2 in /opt/conda/lib/python3.8/site-packages (from -r requirements.txt (line 1)) (1.2.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: scipy>=1.2.1 in /opt/conda/lib/python3.8/site-packages (from -r requirements.txt (line 2)) (1.10.0)\u001b[0m\n",
      "\u001b[34mCollecting SimpleITK>=1.2.0\u001b[0m\n",
      "\u001b[34mDownloading SimpleITK-2.2.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (52.7 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 52.7/52.7 MB 42.9 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting fastai>=2.5.3\u001b[0m\n",
      "\u001b[34mDownloading fastai-2.7.10-py3-none-any.whl (240 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 240.9/240.9 kB 47.1 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting torchio>=0.18.63\u001b[0m\n",
      "\u001b[34mDownloading torchio-0.18.87-py2.py3-none-any.whl (172 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 172.8/172.8 kB 43.8 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.8/site-packages (from scikit-learn>=0.20.2->-r requirements.txt (line 1)) (1.2.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.8/site-packages (from scikit-learn>=0.20.2->-r requirements.txt (line 1)) (3.1.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: numpy>=1.17.3 in /opt/conda/lib/python3.8/site-packages (from scikit-learn>=0.20.2->-r requirements.txt (line 1)) (1.23.5)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pillow>6.0.0 in /opt/conda/lib/python3.8/site-packages (from fastai>=2.5.3->-r requirements.txt (line 4)) (9.4.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: torchvision>=0.8.2 in /opt/conda/lib/python3.8/site-packages (from fastai>=2.5.3->-r requirements.txt (line 4)) (0.13.1+cpu)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: requests in /opt/conda/lib/python3.8/site-packages (from fastai>=2.5.3->-r requirements.txt (line 4)) (2.28.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: torch<1.14,>=1.7 in /opt/conda/lib/python3.8/site-packages (from fastai>=2.5.3->-r requirements.txt (line 4)) (1.12.1+cpu)\u001b[0m\n",
      "\u001b[34mCollecting fastprogress>=0.2.4\u001b[0m\n",
      "\u001b[34mDownloading fastprogress-1.0.3-py3-none-any.whl (12 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pip in /opt/conda/lib/python3.8/site-packages (from fastai>=2.5.3->-r requirements.txt (line 4)) (22.3.1)\u001b[0m\n",
      "\u001b[34mCollecting fastcore<1.6,>=1.4.5\u001b[0m\n",
      "\u001b[34mDownloading fastcore-1.5.28-py3-none-any.whl (67 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 67.6/67.6 kB 19.4 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting spacy<4\u001b[0m\n",
      "\u001b[34mDownloading spacy-3.5.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.7 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 6.7/6.7 MB 113.0 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: matplotlib in /opt/conda/lib/python3.8/site-packages (from fastai>=2.5.3->-r requirements.txt (line 4)) (3.6.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pandas in /opt/conda/lib/python3.8/site-packages (from fastai>=2.5.3->-r requirements.txt (line 4)) (1.5.2)\u001b[0m\n",
      "\u001b[34mCollecting fastdownload<2,>=0.0.5\u001b[0m\n",
      "\u001b[34mDownloading fastdownload-0.0.7-py3-none-any.whl (12 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: packaging in /opt/conda/lib/python3.8/site-packages (from fastai>=2.5.3->-r requirements.txt (line 4)) (22.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pyyaml in /opt/conda/lib/python3.8/site-packages (from fastai>=2.5.3->-r requirements.txt (line 4)) (5.4.1)\u001b[0m\n",
      "\u001b[34mCollecting typer[all]\u001b[0m\n",
      "\u001b[34mDownloading typer-0.7.0-py3-none-any.whl (38 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: tqdm in /opt/conda/lib/python3.8/site-packages (from torchio>=0.18.63->-r requirements.txt (line 5)) (4.64.1)\u001b[0m\n",
      "\u001b[34mCollecting humanize\u001b[0m\n",
      "\u001b[34mDownloading humanize-4.5.0-py3-none-any.whl (110 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 110.0/110.0 kB 32.6 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting nibabel\u001b[0m\n",
      "\u001b[34mDownloading nibabel-5.0.0-py3-none-any.whl (3.3 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 3.3/3.3 MB 112.0 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting Deprecated\u001b[0m\n",
      "\u001b[34mDownloading Deprecated-1.2.13-py2.py3-none-any.whl (9.6 kB)\u001b[0m\n",
      "\u001b[34mCollecting thinc<8.2.0,>=8.1.0\u001b[0m\n",
      "\u001b[34mDownloading thinc-8.1.7-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (828 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 828.9/828.9 kB 75.2 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting srsly<3.0.0,>=2.4.3\u001b[0m\n",
      "\u001b[34mDownloading srsly-2.4.5-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (492 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 492.6/492.6 kB 67.5 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting preshed<3.1.0,>=3.0.2\u001b[0m\n",
      "\u001b[34mDownloading preshed-3.0.8-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (130 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 130.8/130.8 kB 25.9 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting pathy>=0.10.0\u001b[0m\n",
      "\u001b[34mDownloading pathy-0.10.1-py3-none-any.whl (48 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 48.9/48.9 kB 11.0 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting smart-open<7.0.0,>=5.2.1\u001b[0m\n",
      "\u001b[34mDownloading smart_open-6.3.0-py3-none-any.whl (56 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 56.8/56.8 kB 19.3 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: setuptools in /opt/conda/lib/python3.8/site-packages (from spacy<4->fastai>=2.5.3->-r requirements.txt (line 4)) (65.6.3)\u001b[0m\n",
      "\u001b[34mCollecting murmurhash<1.1.0,>=0.28.0\u001b[0m\n",
      "\u001b[34mDownloading murmurhash-1.0.9-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (21 kB)\u001b[0m\n",
      "\u001b[34mCollecting spacy-loggers<2.0.0,>=1.0.0\u001b[0m\n",
      "\u001b[34mDownloading spacy_loggers-1.0.4-py3-none-any.whl (11 kB)\u001b[0m\n",
      "\u001b[34mCollecting catalogue<2.1.0,>=2.0.6\u001b[0m\n",
      "\u001b[34mDownloading catalogue-2.0.8-py3-none-any.whl (17 kB)\u001b[0m\n",
      "\u001b[34mCollecting spacy-legacy<3.1.0,>=3.0.11\u001b[0m\n",
      "\u001b[34mDownloading spacy_legacy-3.0.12-py2.py3-none-any.whl (29 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: jinja2 in /opt/conda/lib/python3.8/site-packages (from spacy<4->fastai>=2.5.3->-r requirements.txt (line 4)) (3.1.2)\u001b[0m\n",
      "\u001b[34mCollecting cymem<2.1.0,>=2.0.2\u001b[0m\n",
      "\u001b[34mDownloading cymem-2.0.7-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (36 kB)\u001b[0m\n",
      "\u001b[34mCollecting langcodes<4.0.0,>=3.2.0\u001b[0m\n",
      "\u001b[34mDownloading langcodes-3.3.0-py3-none-any.whl (181 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 181.6/181.6 kB 40.8 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4\u001b[0m\n",
      "\u001b[34mDownloading pydantic-1.10.4-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.2 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 3.2/3.2 MB 35.4 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting wasabi<1.2.0,>=0.9.1\u001b[0m\n",
      "\u001b[34mDownloading wasabi-1.1.1-py3-none-any.whl (27 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.8/site-packages (from requests->fastai>=2.5.3->-r requirements.txt (line 4)) (3.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.8/site-packages (from requests->fastai>=2.5.3->-r requirements.txt (line 4)) (1.26.13)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: charset-normalizer<3,>=2 in /opt/conda/lib/python3.8/site-packages (from requests->fastai>=2.5.3->-r requirements.txt (line 4)) (2.1.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.8/site-packages (from requests->fastai>=2.5.3->-r requirements.txt (line 4)) (2022.12.7)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.8/site-packages (from torch<1.14,>=1.7->fastai>=2.5.3->-r requirements.txt (line 4)) (4.4.0)\u001b[0m\n",
      "\u001b[34mCollecting wrapt<2,>=1.10\u001b[0m\n",
      "\u001b[34mDownloading wrapt-1.14.1-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (81 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 81.0/81.0 kB 24.8 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.8/site-packages (from matplotlib->fastai>=2.5.3->-r requirements.txt (line 4)) (2.8.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.8/site-packages (from matplotlib->fastai>=2.5.3->-r requirements.txt (line 4)) (1.0.6)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pyparsing>=2.2.1 in /opt/conda/lib/python3.8/site-packages (from matplotlib->fastai>=2.5.3->-r requirements.txt (line 4)) (3.0.9)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.8/site-packages (from matplotlib->fastai>=2.5.3->-r requirements.txt (line 4)) (4.38.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.8/site-packages (from matplotlib->fastai>=2.5.3->-r requirements.txt (line 4)) (1.4.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.8/site-packages (from matplotlib->fastai>=2.5.3->-r requirements.txt (line 4)) (0.11.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.8/site-packages (from pandas->fastai>=2.5.3->-r requirements.txt (line 4)) (2022.7)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: click<9.0.0,>=7.1.1 in /opt/conda/lib/python3.8/site-packages (from typer[all]->torchio>=0.18.63->-r requirements.txt (line 5)) (8.1.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: colorama<0.5.0,>=0.4.3 in /opt/conda/lib/python3.8/site-packages (from typer[all]->torchio>=0.18.63->-r requirements.txt (line 5)) (0.4.4)\u001b[0m\n",
      "\u001b[34mCollecting shellingham<2.0.0,>=1.3.0\u001b[0m\n",
      "\u001b[34mDownloading shellingham-1.5.0.post1-py2.py3-none-any.whl (9.4 kB)\u001b[0m\n",
      "\u001b[34mCollecting rich<13.0.0,>=10.11.0\u001b[0m\n",
      "\u001b[34mDownloading rich-12.6.0-py3-none-any.whl (237 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 237.5/237.5 kB 52.5 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.8/site-packages (from python-dateutil>=2.7->matplotlib->fastai>=2.5.3->-r requirements.txt (line 4)) (1.16.0)\u001b[0m\n",
      "\u001b[34mCollecting commonmark<0.10.0,>=0.9.0\u001b[0m\n",
      "\u001b[34mDownloading commonmark-0.9.1-py2.py3-none-any.whl (51 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 51.1/51.1 kB 14.4 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pygments<3.0.0,>=2.6.0 in /opt/conda/lib/python3.8/site-packages (from rich<13.0.0,>=10.11.0->typer[all]->torchio>=0.18.63->-r requirements.txt (line 5)) (2.14.0)\u001b[0m\n",
      "\u001b[34mCollecting confection<1.0.0,>=0.0.1\u001b[0m\n",
      "\u001b[34mDownloading confection-0.0.4-py3-none-any.whl (32 kB)\u001b[0m\n",
      "\u001b[34mCollecting blis<0.8.0,>=0.7.8\u001b[0m\n",
      "\u001b[34mDownloading blis-0.7.9-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (10.2 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 10.2/10.2 MB 110.6 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.8/site-packages (from jinja2->spacy<4->fastai>=2.5.3->-r requirements.txt (line 4)) (2.1.1)\u001b[0m\n",
      "\u001b[34mInstalling collected packages: SimpleITK, cymem, commonmark, wrapt, wasabi, typer, spacy-loggers, spacy-legacy, smart-open, shellingham, rich, pydantic, nibabel, murmurhash, langcodes, humanize, fastprogress, fastcore, catalogue, blis, srsly, preshed, pathy, fastdownload, Deprecated, torchio, confection, thinc, spacy, fastai\u001b[0m\n",
      "\u001b[34mSuccessfully installed Deprecated-1.2.13 SimpleITK-2.2.1 blis-0.7.9 catalogue-2.0.8 commonmark-0.9.1 confection-0.0.4 cymem-2.0.7 fastai-2.7.10 fastcore-1.5.28 fastdownload-0.0.7 fastprogress-1.0.3 humanize-4.5.0 langcodes-3.3.0 murmurhash-1.0.9 nibabel-5.0.0 pathy-0.10.1 preshed-3.0.8 pydantic-1.10.4 rich-12.6.0 shellingham-1.5.0.post1 smart-open-6.3.0 spacy-3.5.0 spacy-legacy-3.0.12 spacy-loggers-1.0.4 srsly-2.4.5 thinc-8.1.7 torchio-0.18.87 typer-0.7.0 wasabi-1.1.1 wrapt-1.14.1\u001b[0m\n",
      "\u001b[34mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[34m[notice] A new release of pip available: 22.3.1 -> 23.0\u001b[0m\n",
      "\u001b[34m[notice] To update, run: pip install --upgrade pip\u001b[0m\n",
      "\u001b[34m2023-02-02 12:57:22,390 sagemaker-training-toolkit INFO     Waiting for the process to finish and give a return code.\u001b[0m\n",
      "\u001b[34m2023-02-02 12:57:22,390 sagemaker-training-toolkit INFO     Done waiting for a return code. Received 0 from exiting process.\u001b[0m\n",
      "\u001b[34m2023-02-02 12:57:22,393 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2023-02-02 12:57:22,396 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2023-02-02 12:57:22,412 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2023-02-02 12:57:22,414 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2023-02-02 12:57:22,427 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2023-02-02 12:57:22,430 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2023-02-02 12:57:22,441 sagemaker-training-toolkit INFO     Invoking user script\u001b[0m\n",
      "\u001b[34mTraining Env:\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"dataset\": \"/opt/ml/input/data/dataset\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"current_instance_group\": \"homogeneousCluster\",\n",
      "    \"current_instance_group_hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"current_instance_type\": \"ml.m5.large\",\n",
      "    \"distribution_hosts\": [],\n",
      "    \"distribution_instance_groups\": [],\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {},\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"dataset\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"instance_groups\": [\n",
      "        \"homogeneousCluster\"\n",
      "    ],\n",
      "    \"instance_groups_dict\": {\n",
      "        \"homogeneousCluster\": {\n",
      "            \"instance_group_name\": \"homogeneousCluster\",\n",
      "            \"instance_type\": \"ml.m5.large\",\n",
      "            \"hosts\": [\n",
      "                \"algo-1\"\n",
      "            ]\n",
      "        }\n",
      "    },\n",
      "    \"is_hetero\": false,\n",
      "    \"is_master\": true,\n",
      "    \"is_modelparallel_enabled\": null,\n",
      "    \"is_smddpmprun_installed\": false,\n",
      "    \"job_name\": \"pytorch-training-2023-02-02-12-54-21-116\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-east-1-668452981977/pytorch-training-2023-02-02-12-54-21-116/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"do_preprocess\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 2,\n",
      "    \"num_gpus\": 0,\n",
      "    \"num_neurons\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"current_instance_type\": \"ml.m5.large\",\n",
      "        \"current_group_name\": \"homogeneousCluster\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"instance_groups\": [\n",
      "            {\n",
      "                \"instance_group_name\": \"homogeneousCluster\",\n",
      "                \"instance_type\": \"ml.m5.large\",\n",
      "                \"hosts\": [\n",
      "                    \"algo-1\"\n",
      "                ]\n",
      "            }\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"do_preprocess.py\"\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34mEnvironment variables:\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=do_preprocess.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.m5.large\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.m5.large\"}],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"dataset\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"dataset\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_TYPE=ml.m5.large\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_GROUP=homogeneousCluster\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_GROUP_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_INSTANCE_GROUPS=[\"homogeneousCluster\"]\u001b[0m\n",
      "\u001b[34mSM_INSTANCE_GROUPS_DICT={\"homogeneousCluster\":{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.m5.large\"}}\u001b[0m\n",
      "\u001b[34mSM_DISTRIBUTION_INSTANCE_GROUPS=[]\u001b[0m\n",
      "\u001b[34mSM_IS_HETERO=false\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=do_preprocess\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=2\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=0\u001b[0m\n",
      "\u001b[34mSM_NUM_NEURONS=0\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-us-east-1-668452981977/pytorch-training-2023-02-02-12-54-21-116/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"dataset\":\"/opt/ml/input/data/dataset\"},\"current_host\":\"algo-1\",\"current_instance_group\":\"homogeneousCluster\",\"current_instance_group_hosts\":[\"algo-1\"],\"current_instance_type\":\"ml.m5.large\",\"distribution_hosts\":[],\"distribution_instance_groups\":[],\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"dataset\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"instance_groups\":[\"homogeneousCluster\"],\"instance_groups_dict\":{\"homogeneousCluster\":{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.m5.large\"}},\"is_hetero\":false,\"is_master\":true,\"is_modelparallel_enabled\":null,\"is_smddpmprun_installed\":false,\"job_name\":\"pytorch-training-2023-02-02-12-54-21-116\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-1-668452981977/pytorch-training-2023-02-02-12-54-21-116/source/sourcedir.tar.gz\",\"module_name\":\"do_preprocess\",\"network_interface_name\":\"eth0\",\"num_cpus\":2,\"num_gpus\":0,\"num_neurons\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.m5.large\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.m5.large\"}],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"do_preprocess.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_DATASET=/opt/ml/input/data/dataset\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python38.zip:/opt/conda/lib/python3.8:/opt/conda/lib/python3.8/lib-dynload:/opt/conda/lib/python3.8/site-packages:/opt/conda/lib/python3.8/site-packages/smdebug-1.0.24b20230106-py3.8.egg:/opt/conda/lib/python3.8/site-packages/pyinstrument-3.4.2-py3.8.egg:/opt/conda/lib/python3.8/site-packages/pyinstrument_cext-0.2.4-py3.8-linux-x86_64.egg\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python3.8 do_preprocess.py\u001b[0m\n",
      "\u001b[34m2023-02-02 12:57:23,081 sagemaker-training-toolkit INFO     Exceptions not imported for SageMaker TF as Tensorflow is not installed.\u001b[0m\n",
      "\u001b[34mImage /opt/ml/input/data/dataset/data/mha/22.mha processed.\u001b[0m\n",
      "\u001b[34mImage /opt/ml/input/data/dataset/data/mha/17.mha processed.\u001b[0m\n",
      "\u001b[34mImage /opt/ml/input/data/dataset/data/mha/6.mha processed.\u001b[0m\n",
      "\u001b[34m2023-02-02 12:57:28,635 sagemaker-training-toolkit INFO     Waiting for the process to finish and give a return code.\u001b[0m\n",
      "\u001b[34m2023-02-02 12:57:28,635 sagemaker-training-toolkit INFO     Done waiting for a return code. Received 0 from exiting process.\u001b[0m\n",
      "\u001b[34m2023-02-02 12:57:28,636 sagemaker-training-toolkit INFO     Reporting training SUCCESS\u001b[0m\n",
      "\n",
      "2023-02-02 12:57:51 Uploading - Uploading generated training model\n",
      "2023-02-02 12:57:51 Completed - Training job completed\n",
      "Training seconds: 127\n",
      "Billable seconds: 127\n"
     ]
    }
   ],
   "source": [
    "# Do preprocessing\n",
    "\n",
    "estimator = PyTorch(  #Pytorch is not actually needed for preprocessing, \n",
    "    entry_point='do_preprocess.py',  # A python file in source_dir\n",
    "    source_dir=os.getcwd(),  # local path (in SageMaker Studio)\n",
    "    role=get_execution_role(),\n",
    "    instance_type='ml.m5.large',\n",
    "    instance_count=1,\n",
    "    # volume_size=500,  # Scratch volume mounted at /tmp/ in GB\n",
    "    framework_version='1.12',\n",
    "    py_version='py38',\n",
    "    max_run=60,  # in seconds, maximum is 5 days\n",
    "    checkpoint_s3_uri=preprocessed_location,  # gets pulled from to checkpoint_local_path at the start of training, and pushed to at the end\n",
    "    checkpoint_local_path= '/preprocessed/',\n",
    ")\n",
    "\n",
    "estimator.fit(\n",
    "    inputs={  # Each input folder passed must have contents. \n",
    "        'dataset': dataset_location,\n",
    "    }  # Paths are available on the training instance in environment variables named SM_CHANNEL_<KEY>, e.g. SM_CHANNEL_IMAGES\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f6be4a3a-6ecb-4ef4-aaca-71b29d695ab6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-02-02 12:58:13 Starting - Starting the training job...\n",
      "2023-02-02 12:58:39 Starting - Preparing the instances for trainingProfilerReport-1675342692: InProgress\n",
      "......\n",
      "2023-02-02 12:59:40 Downloading - Downloading input data...\n",
      "2023-02-02 13:00:00 Training - Downloading the training image....................\u001b[34mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[34mbash: no job control in this shell\u001b[0m\n",
      "\u001b[34m2023-02-02 13:03:29,425 sagemaker-training-toolkit INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
      "\u001b[34m2023-02-02 13:03:29,445 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2023-02-02 13:03:29,456 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n",
      "\u001b[34m2023-02-02 13:03:29,459 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[34m2023-02-02 13:03:30,316 sagemaker-training-toolkit INFO     Installing dependencies from requirements.txt:\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python3.8 -m pip install -r requirements.txt\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: scikit-learn>=0.20.2 in /opt/conda/lib/python3.8/site-packages (from -r requirements.txt (line 1)) (1.2.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: scipy>=1.2.1 in /opt/conda/lib/python3.8/site-packages (from -r requirements.txt (line 2)) (1.10.0)\u001b[0m\n",
      "\u001b[34mCollecting SimpleITK>=1.2.0\u001b[0m\n",
      "\u001b[34mDownloading SimpleITK-2.2.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (52.7 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 52.7/52.7 MB 38.9 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting fastai>=2.5.3\u001b[0m\n",
      "\u001b[34mDownloading fastai-2.7.10-py3-none-any.whl (240 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 240.9/240.9 kB 28.7 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting torchio>=0.18.63\u001b[0m\n",
      "\u001b[34mDownloading torchio-0.18.87-py2.py3-none-any.whl (172 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 172.8/172.8 kB 30.8 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: numpy>=1.17.3 in /opt/conda/lib/python3.8/site-packages (from scikit-learn>=0.20.2->-r requirements.txt (line 1)) (1.23.5)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.8/site-packages (from scikit-learn>=0.20.2->-r requirements.txt (line 1)) (1.2.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.8/site-packages (from scikit-learn>=0.20.2->-r requirements.txt (line 1)) (3.1.0)\u001b[0m\n",
      "\u001b[34mCollecting fastprogress>=0.2.4\u001b[0m\n",
      "\u001b[34mDownloading fastprogress-1.0.3-py3-none-any.whl (12 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pyyaml in /opt/conda/lib/python3.8/site-packages (from fastai>=2.5.3->-r requirements.txt (line 4)) (5.4.1)\u001b[0m\n",
      "\u001b[34mCollecting fastcore<1.6,>=1.4.5\u001b[0m\n",
      "\u001b[34mDownloading fastcore-1.5.28-py3-none-any.whl (67 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 67.6/67.6 kB 21.3 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pip in /opt/conda/lib/python3.8/site-packages (from fastai>=2.5.3->-r requirements.txt (line 4)) (22.3.1)\u001b[0m\n",
      "\u001b[34mCollecting spacy<4\u001b[0m\n",
      "\u001b[34mDownloading spacy-3.5.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.7 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 6.7/6.7 MB 114.9 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pandas in /opt/conda/lib/python3.8/site-packages (from fastai>=2.5.3->-r requirements.txt (line 4)) (1.5.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: matplotlib in /opt/conda/lib/python3.8/site-packages (from fastai>=2.5.3->-r requirements.txt (line 4)) (3.6.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: torchvision>=0.8.2 in /opt/conda/lib/python3.8/site-packages (from fastai>=2.5.3->-r requirements.txt (line 4)) (0.13.1+cu113)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: packaging in /opt/conda/lib/python3.8/site-packages (from fastai>=2.5.3->-r requirements.txt (line 4)) (22.0)\u001b[0m\n",
      "\u001b[34mCollecting fastdownload<2,>=0.0.5\u001b[0m\n",
      "\u001b[34mDownloading fastdownload-0.0.7-py3-none-any.whl (12 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: requests in /opt/conda/lib/python3.8/site-packages (from fastai>=2.5.3->-r requirements.txt (line 4)) (2.28.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: torch<1.14,>=1.7 in /opt/conda/lib/python3.8/site-packages (from fastai>=2.5.3->-r requirements.txt (line 4)) (1.12.1+cu113)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pillow>6.0.0 in /opt/conda/lib/python3.8/site-packages (from fastai>=2.5.3->-r requirements.txt (line 4)) (9.4.0)\u001b[0m\n",
      "\u001b[34mCollecting nibabel\u001b[0m\n",
      "\u001b[34mDownloading nibabel-5.0.0-py3-none-any.whl (3.3 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 3.3/3.3 MB 35.7 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting humanize\u001b[0m\n",
      "\u001b[34mDownloading humanize-4.5.0-py3-none-any.whl (110 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 110.0/110.0 kB 26.1 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting typer[all]\u001b[0m\n",
      "\u001b[34mDownloading typer-0.7.0-py3-none-any.whl (38 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: tqdm in /opt/conda/lib/python3.8/site-packages (from torchio>=0.18.63->-r requirements.txt (line 5)) (4.64.1)\u001b[0m\n",
      "\u001b[34mCollecting Deprecated\u001b[0m\n",
      "\u001b[34mDownloading Deprecated-1.2.13-py2.py3-none-any.whl (9.6 kB)\u001b[0m\n",
      "\u001b[34mCollecting murmurhash<1.1.0,>=0.28.0\u001b[0m\n",
      "\u001b[34mDownloading murmurhash-1.0.9-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (21 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: setuptools in /opt/conda/lib/python3.8/site-packages (from spacy<4->fastai>=2.5.3->-r requirements.txt (line 4)) (65.6.3)\u001b[0m\n",
      "\u001b[34mCollecting srsly<3.0.0,>=2.4.3\u001b[0m\n",
      "\u001b[34mDownloading srsly-2.4.5-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (492 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 492.6/492.6 kB 71.0 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting langcodes<4.0.0,>=3.2.0\u001b[0m\n",
      "\u001b[34mDownloading langcodes-3.3.0-py3-none-any.whl (181 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 181.6/181.6 kB 41.2 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting cymem<2.1.0,>=2.0.2\u001b[0m\n",
      "\u001b[34mDownloading cymem-2.0.7-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (36 kB)\u001b[0m\n",
      "\u001b[34mCollecting catalogue<2.1.0,>=2.0.6\u001b[0m\n",
      "\u001b[34mDownloading catalogue-2.0.8-py3-none-any.whl (17 kB)\u001b[0m\n",
      "\u001b[34mCollecting pathy>=0.10.0\u001b[0m\n",
      "\u001b[34mDownloading pathy-0.10.1-py3-none-any.whl (48 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 48.9/48.9 kB 13.8 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4\u001b[0m\n",
      "\u001b[34mDownloading pydantic-1.10.4-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.2 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 3.2/3.2 MB 45.9 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting spacy-loggers<2.0.0,>=1.0.0\u001b[0m\n",
      "\u001b[34mDownloading spacy_loggers-1.0.4-py3-none-any.whl (11 kB)\u001b[0m\n",
      "\u001b[34mCollecting thinc<8.2.0,>=8.1.0\u001b[0m\n",
      "\u001b[34mDownloading thinc-8.1.7-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (828 kB)\u001b[0m\n",
      "\n",
      "2023-02-02 13:03:41 Training - Training image download completed. Training in progress.\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 828.9/828.9 kB 66.5 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting smart-open<7.0.0,>=5.2.1\u001b[0m\n",
      "\u001b[34mDownloading smart_open-6.3.0-py3-none-any.whl (56 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 56.8/56.8 kB 1.3 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: jinja2 in /opt/conda/lib/python3.8/site-packages (from spacy<4->fastai>=2.5.3->-r requirements.txt (line 4)) (3.1.2)\u001b[0m\n",
      "\u001b[34mCollecting preshed<3.1.0,>=3.0.2\u001b[0m\n",
      "\u001b[34mDownloading preshed-3.0.8-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (130 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 130.8/130.8 kB 27.0 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting wasabi<1.2.0,>=0.9.1\u001b[0m\n",
      "\u001b[34mDownloading wasabi-1.1.1-py3-none-any.whl (27 kB)\u001b[0m\n",
      "\u001b[34mCollecting spacy-legacy<3.1.0,>=3.0.11\u001b[0m\n",
      "\u001b[34mDownloading spacy_legacy-3.0.12-py2.py3-none-any.whl (29 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.8/site-packages (from requests->fastai>=2.5.3->-r requirements.txt (line 4)) (1.26.13)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.8/site-packages (from requests->fastai>=2.5.3->-r requirements.txt (line 4)) (3.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: charset-normalizer<3,>=2 in /opt/conda/lib/python3.8/site-packages (from requests->fastai>=2.5.3->-r requirements.txt (line 4)) (2.1.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.8/site-packages (from requests->fastai>=2.5.3->-r requirements.txt (line 4)) (2022.12.7)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.8/site-packages (from torch<1.14,>=1.7->fastai>=2.5.3->-r requirements.txt (line 4)) (4.4.0)\u001b[0m\n",
      "\u001b[34mCollecting wrapt<2,>=1.10\u001b[0m\n",
      "\u001b[34mDownloading wrapt-1.14.1-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (81 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 81.0/81.0 kB 18.1 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.8/site-packages (from matplotlib->fastai>=2.5.3->-r requirements.txt (line 4)) (2.8.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pyparsing>=2.2.1 in /opt/conda/lib/python3.8/site-packages (from matplotlib->fastai>=2.5.3->-r requirements.txt (line 4)) (3.0.9)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.8/site-packages (from matplotlib->fastai>=2.5.3->-r requirements.txt (line 4)) (0.11.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.8/site-packages (from matplotlib->fastai>=2.5.3->-r requirements.txt (line 4)) (1.4.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.8/site-packages (from matplotlib->fastai>=2.5.3->-r requirements.txt (line 4)) (1.0.6)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.8/site-packages (from matplotlib->fastai>=2.5.3->-r requirements.txt (line 4)) (4.38.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.8/site-packages (from pandas->fastai>=2.5.3->-r requirements.txt (line 4)) (2022.7)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: click<9.0.0,>=7.1.1 in /opt/conda/lib/python3.8/site-packages (from typer[all]->torchio>=0.18.63->-r requirements.txt (line 5)) (8.1.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: colorama<0.5.0,>=0.4.3 in /opt/conda/lib/python3.8/site-packages (from typer[all]->torchio>=0.18.63->-r requirements.txt (line 5)) (0.4.4)\u001b[0m\n",
      "\u001b[34mCollecting shellingham<2.0.0,>=1.3.0\u001b[0m\n",
      "\u001b[34mDownloading shellingham-1.5.0.post1-py2.py3-none-any.whl (9.4 kB)\u001b[0m\n",
      "\u001b[34mCollecting rich<13.0.0,>=10.11.0\u001b[0m\n",
      "\u001b[34mDownloading rich-12.6.0-py3-none-any.whl (237 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 237.5/237.5 kB 46.3 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.8/site-packages (from python-dateutil>=2.7->matplotlib->fastai>=2.5.3->-r requirements.txt (line 4)) (1.16.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pygments<3.0.0,>=2.6.0 in /opt/conda/lib/python3.8/site-packages (from rich<13.0.0,>=10.11.0->typer[all]->torchio>=0.18.63->-r requirements.txt (line 5)) (2.14.0)\u001b[0m\n",
      "\u001b[34mCollecting commonmark<0.10.0,>=0.9.0\u001b[0m\n",
      "\u001b[34mDownloading commonmark-0.9.1-py2.py3-none-any.whl (51 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 51.1/51.1 kB 16.7 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting confection<1.0.0,>=0.0.1\u001b[0m\n",
      "\u001b[34mDownloading confection-0.0.4-py3-none-any.whl (32 kB)\u001b[0m\n",
      "\u001b[34mCollecting blis<0.8.0,>=0.7.8\u001b[0m\n",
      "\u001b[34mDownloading blis-0.7.9-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (10.2 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 10.2/10.2 MB 113.4 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.8/site-packages (from jinja2->spacy<4->fastai>=2.5.3->-r requirements.txt (line 4)) (2.1.1)\u001b[0m\n",
      "\u001b[34mInstalling collected packages: SimpleITK, cymem, commonmark, wrapt, wasabi, typer, spacy-loggers, spacy-legacy, smart-open, shellingham, rich, pydantic, nibabel, murmurhash, langcodes, humanize, fastprogress, fastcore, catalogue, blis, srsly, preshed, pathy, fastdownload, Deprecated, torchio, confection, thinc, spacy, fastai\u001b[0m\n",
      "\u001b[34mSuccessfully installed Deprecated-1.2.13 SimpleITK-2.2.1 blis-0.7.9 catalogue-2.0.8 commonmark-0.9.1 confection-0.0.4 cymem-2.0.7 fastai-2.7.10 fastcore-1.5.28 fastdownload-0.0.7 fastprogress-1.0.3 humanize-4.5.0 langcodes-3.3.0 murmurhash-1.0.9 nibabel-5.0.0 pathy-0.10.1 preshed-3.0.8 pydantic-1.10.4 rich-12.6.0 shellingham-1.5.0.post1 smart-open-6.3.0 spacy-3.5.0 spacy-legacy-3.0.12 spacy-loggers-1.0.4 srsly-2.4.5 thinc-8.1.7 torchio-0.18.87 typer-0.7.0 wasabi-1.1.1 wrapt-1.14.1\u001b[0m\n",
      "\u001b[34mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[34m[notice] A new release of pip available: 22.3.1 -> 23.0\u001b[0m\n",
      "\u001b[34m[notice] To update, run: pip install --upgrade pip\u001b[0m\n",
      "\u001b[34m2023-02-02 13:03:40,159 sagemaker-training-toolkit INFO     Waiting for the process to finish and give a return code.\u001b[0m\n",
      "\u001b[34m2023-02-02 13:03:40,159 sagemaker-training-toolkit INFO     Done waiting for a return code. Received 0 from exiting process.\u001b[0m\n",
      "\u001b[34m2023-02-02 13:03:40,183 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2023-02-02 13:03:40,216 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2023-02-02 13:03:40,249 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2023-02-02 13:03:40,261 sagemaker-training-toolkit INFO     Invoking user script\u001b[0m\n",
      "\u001b[34mTraining Env:\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"preprocessed\": \"/opt/ml/input/data/preprocessed\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"current_instance_group\": \"homogeneousCluster\",\n",
      "    \"current_instance_group_hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"current_instance_type\": \"ml.g4dn.xlarge\",\n",
      "    \"distribution_hosts\": [],\n",
      "    \"distribution_instance_groups\": [],\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {},\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"preprocessed\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"instance_groups\": [\n",
      "        \"homogeneousCluster\"\n",
      "    ],\n",
      "    \"instance_groups_dict\": {\n",
      "        \"homogeneousCluster\": {\n",
      "            \"instance_group_name\": \"homogeneousCluster\",\n",
      "            \"instance_type\": \"ml.g4dn.xlarge\",\n",
      "            \"hosts\": [\n",
      "                \"algo-1\"\n",
      "            ]\n",
      "        }\n",
      "    },\n",
      "    \"is_hetero\": false,\n",
      "    \"is_master\": true,\n",
      "    \"is_modelparallel_enabled\": null,\n",
      "    \"is_smddpmprun_installed\": true,\n",
      "    \"job_name\": \"pytorch-training-2023-02-02-12-58-09-332\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-east-1-668452981977/pytorch-training-2023-02-02-12-58-09-332/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"train\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 4,\n",
      "    \"num_gpus\": 1,\n",
      "    \"num_neurons\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"current_instance_type\": \"ml.g4dn.xlarge\",\n",
      "        \"current_group_name\": \"homogeneousCluster\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"instance_groups\": [\n",
      "            {\n",
      "                \"instance_group_name\": \"homogeneousCluster\",\n",
      "                \"instance_type\": \"ml.g4dn.xlarge\",\n",
      "                \"hosts\": [\n",
      "                    \"algo-1\"\n",
      "                ]\n",
      "            }\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"train.py\"\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34mEnvironment variables:\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=train.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.g4dn.xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g4dn.xlarge\"}],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"preprocessed\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"preprocessed\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_TYPE=ml.g4dn.xlarge\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_GROUP=homogeneousCluster\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_GROUP_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_INSTANCE_GROUPS=[\"homogeneousCluster\"]\u001b[0m\n",
      "\u001b[34mSM_INSTANCE_GROUPS_DICT={\"homogeneousCluster\":{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g4dn.xlarge\"}}\u001b[0m\n",
      "\u001b[34mSM_DISTRIBUTION_INSTANCE_GROUPS=[]\u001b[0m\n",
      "\u001b[34mSM_IS_HETERO=false\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=train\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=4\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=1\u001b[0m\n",
      "\u001b[34mSM_NUM_NEURONS=0\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-us-east-1-668452981977/pytorch-training-2023-02-02-12-58-09-332/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"preprocessed\":\"/opt/ml/input/data/preprocessed\"},\"current_host\":\"algo-1\",\"current_instance_group\":\"homogeneousCluster\",\"current_instance_group_hosts\":[\"algo-1\"],\"current_instance_type\":\"ml.g4dn.xlarge\",\"distribution_hosts\":[],\"distribution_instance_groups\":[],\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"preprocessed\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"instance_groups\":[\"homogeneousCluster\"],\"instance_groups_dict\":{\"homogeneousCluster\":{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g4dn.xlarge\"}},\"is_hetero\":false,\"is_master\":true,\"is_modelparallel_enabled\":null,\"is_smddpmprun_installed\":true,\"job_name\":\"pytorch-training-2023-02-02-12-58-09-332\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-1-668452981977/pytorch-training-2023-02-02-12-58-09-332/source/sourcedir.tar.gz\",\"module_name\":\"train\",\"network_interface_name\":\"eth0\",\"num_cpus\":4,\"num_gpus\":1,\"num_neurons\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.g4dn.xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g4dn.xlarge\"}],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"train.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_PREPROCESSED=/opt/ml/input/data/preprocessed\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python38.zip:/opt/conda/lib/python3.8:/opt/conda/lib/python3.8/lib-dynload:/opt/conda/lib/python3.8/site-packages:/opt/conda/lib/python3.8/site-packages/smdebug-1.0.24b20230106-py3.8.egg:/opt/conda/lib/python3.8/site-packages/pyinstrument-3.4.2-py3.8.egg:/opt/conda/lib/python3.8/site-packages/pyinstrument_cext-0.2.4-py3.8-linux-x86_64.egg:/opt/conda/lib/python3.8/site-packages/flash_attn-0.1-py3.8-linux-x86_64.egg:/opt/conda/lib/python3.8/site-packages/einops-0.6.0-py3.8.egg\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python3.8 train.py\u001b[0m\n",
      "\u001b[34m2023-02-02 13:03:43,054 sagemaker-training-toolkit INFO     Exceptions not imported for SageMaker TF as Tensorflow is not installed.\u001b[0m\n",
      "\u001b[34mCopying preprocessed data to /tmp...\u001b[0m\n",
      "\u001b[34mCopying done.\u001b[0m\n",
      "\u001b[34m█#015epoch     train_loss  valid_loss  acc_probcovid  roc_probcovid  acc_probseverecovid  roc_probseverecovid  time\u001b[0m\n",
      "\u001b[34m█\u001b[0m\n",
      "\u001b[34mEpoch 1/40 : |----------------------------------------| 0.00% [0/120 00:00<?]\u001b[0m\n",
      "\u001b[34m[2023-02-02 13:03:49.981 algo-1:77 INFO utils.py:28] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.8/site-packages/smdebug-1.0.24b20230106-py3.8.egg/smdebug/profiler/system_metrics_reader.py:78: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.8/site-packages/smdebug-1.0.24b20230106-py3.8.egg/smdebug/profiler/system_metrics_reader.py:78: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\u001b[0m\n",
      "\u001b[34m[2023-02-02 13:03:50.131 algo-1:77 INFO profiler_config_parser.py:111] User has disabled profiler.\u001b[0m\n",
      "\u001b[34mEpoch 1/40 : |----------------------------------------| 0.83% [1/120 00:06<11:59]\u001b[0m\n",
      "\u001b[34mEpoch 1/40 : |----------------------------------------| 1.67% [2/120 00:07<07:06 0.6983]\u001b[0m\n",
      "\u001b[34mEpoch 1/40 : |█---------------------------------------| 2.50% [3/120 00:08<05:30 0.6142]\u001b[0m\n",
      "\u001b[34mEpoch 1/40 : |█---------------------------------------| 3.33% [4/120 00:09<04:40 0.6302]\u001b[0m\n",
      "\u001b[34mEpoch 1/40 : |█---------------------------------------| 4.17% [5/120 00:10<04:11 0.5223]\u001b[0m\n",
      "\u001b[34mEpoch 1/40 : |██--------------------------------------| 5.00% [6/120 00:12<03:50 0.4959]\u001b[0m\n",
      "\u001b[34mEpoch 1/40 : |██--------------------------------------| 5.83% [7/120 00:13<03:35 0.4927]\u001b[0m\n",
      "\u001b[34mEpoch 1/40 : |██--------------------------------------| 6.67% [8/120 00:14<03:23 0.5277]\u001b[0m\n",
      "\u001b[34mEpoch 1/40 : |███-------------------------------------| 7.50% [9/120 00:15<03:14 0.5986]\u001b[0m\n",
      "\u001b[34mEpoch 1/40 : |███-------------------------------------| 8.33% [10/120 00:16<03:06 0.5841]\u001b[0m\n",
      "\u001b[34mEpoch 1/40 : |███-------------------------------------| 9.17% [11/120 00:18<03:00 0.5637]\u001b[0m\n",
      "\u001b[34mEpoch 1/40 : |████------------------------------------| 10.00% [12/120 00:19<02:54 0.5230]\u001b[0m\n",
      "\u001b[34mEpoch 1/40 : |████------------------------------------| 10.83% [13/120 00:20<02:49 0.5029]\u001b[0m\n",
      "\u001b[34mEpoch 1/40 : |████------------------------------------| 11.67% [14/120 00:21<02:45 0.5282]\u001b[0m\n",
      "\u001b[34mEpoch 1/40 : |█████-----------------------------------| 12.50% [15/120 00:23<02:41 0.5306]\u001b[0m\n",
      "\u001b[34mEpoch 1/40 : |█████-----------------------------------| 13.33% [16/120 00:24<02:37 0.4983]\u001b[0m\n",
      "\u001b[34mEpoch 1/40 : |█████-----------------------------------| 14.17% [17/120 00:25<02:34 0.4681]\u001b[0m\n",
      "\u001b[34mEpoch 1/40 : |██████----------------------------------| 15.00% [18/120 00:26<02:31 0.4402]\u001b[0m\n",
      "\u001b[34mEpoch 1/40 : |██████----------------------------------| 15.83% [19/120 00:27<02:28 0.4282]\u001b[0m\n",
      "\u001b[34mEpoch 1/40 : |██████----------------------------------| 16.67% [20/120 00:29<02:25 0.4304]\u001b[0m\n",
      "\u001b[34mEpoch 1/40 : |███████---------------------------------| 17.50% [21/120 00:30<02:22 0.4164]\u001b[0m\n",
      "\u001b[34mEpoch 1/40 : |███████---------------------------------| 18.33% [22/120 00:31<02:20 0.4021]\u001b[0m\n",
      "\u001b[34mEpoch 1/40 : |███████---------------------------------| 19.17% [23/120 00:32<02:18 0.3829]\u001b[0m\n",
      "\u001b[34mEpoch 1/40 : |████████--------------------------------| 20.00% [24/120 00:33<02:15 0.3787]\u001b[0m\n",
      "\u001b[34mEpoch 1/40 : |████████--------------------------------| 20.83% [25/120 00:35<02:13 0.3668]\u001b[0m\n",
      "\u001b[34mEpoch 1/40 : |████████--------------------------------| 21.67% [26/120 00:36<02:11 0.3664]\u001b[0m\n",
      "\u001b[34mEpoch 1/40 : |█████████-------------------------------| 22.50% [27/120 00:37<02:09 0.3645]\u001b[0m\n",
      "\u001b[34mEpoch 1/40 : |█████████-------------------------------| 23.33% [28/120 00:38<02:07 0.3643]\u001b[0m\n",
      "\u001b[34mEpoch 1/40 : |█████████-------------------------------| 24.17% [29/120 00:40<02:05 0.3853]\u001b[0m\n",
      "\u001b[34mEpoch 1/40 : |██████████------------------------------| 25.00% [30/120 00:41<02:03 0.3762]\u001b[0m\n",
      "\u001b[34mEpoch 1/40 : |██████████------------------------------| 25.83% [31/120 00:42<02:01 0.3669]\u001b[0m\n",
      "\u001b[34mEpoch 1/40 : |██████████------------------------------| 26.67% [32/120 00:43<02:00 0.3577]\u001b[0m\n",
      "\u001b[34mEpoch 1/40 : |███████████-----------------------------| 27.50% [33/120 00:44<01:58 0.3615]\u001b[0m\n",
      "\u001b[34mEpoch 1/40 : |███████████-----------------------------| 28.33% [34/120 00:46<01:56 0.3571]\u001b[0m\n",
      "\u001b[34mEpoch 1/40 : |███████████-----------------------------| 29.17% [35/120 00:47<01:54 0.3441]\u001b[0m\n",
      "\u001b[34mEpoch 1/40 : |████████████----------------------------| 30.00% [36/120 00:48<01:53 0.3348]\u001b[0m\n",
      "\u001b[34mEpoch 1/40 : |████████████----------------------------| 30.83% [37/120 00:49<01:51 0.3231]\u001b[0m\n",
      "\u001b[34mEpoch 1/40 : |████████████----------------------------| 31.67% [38/120 00:50<01:49 0.3191]\u001b[0m\n",
      "\u001b[34mEpoch 1/40 : |█████████████---------------------------| 32.50% [39/120 00:52<01:48 0.3111]\u001b[0m\n",
      "\u001b[34mEpoch 1/40 : |█████████████---------------------------| 33.33% [40/120 00:53<01:46 0.3141]\u001b[0m\n",
      "\u001b[34mEpoch 1/40 : |█████████████---------------------------| 34.17% [41/120 00:54<01:45 0.3039]\u001b[0m\n",
      "\u001b[34mEpoch 1/40 : |██████████████--------------------------| 35.00% [42/120 00:55<01:43 0.2963]\u001b[0m\n",
      "\u001b[34mEpoch 1/40 : |██████████████--------------------------| 35.83% [43/120 00:56<01:41 0.2869]\u001b[0m\n",
      "\u001b[34mEpoch 1/40 : |██████████████--------------------------| 36.67% [44/120 00:58<01:40 0.2812]\u001b[0m\n",
      "\u001b[34mEpoch 1/40 : |███████████████-------------------------| 37.50% [45/120 00:59<01:38 0.2819]\u001b[0m\n",
      "\u001b[34mEpoch 1/40 : |███████████████-------------------------| 38.33% [46/120 01:00<01:37 0.2733]\u001b[0m\n",
      "\u001b[34mEpoch 1/40 : |███████████████-------------------------| 39.17% [47/120 01:01<01:35 0.2651]\u001b[0m\n",
      "\u001b[34mEpoch 1/40 : |████████████████------------------------| 40.00% [48/120 01:02<01:34 0.2572]\u001b[0m\n",
      "\u001b[34mEpoch 1/40 : |████████████████------------------------| 40.83% [49/120 01:04<01:32 0.2496]\u001b[0m\n",
      "\u001b[34mEpoch 1/40 : |████████████████------------------------| 41.67% [50/120 01:05<01:31 0.2445]\u001b[0m\n",
      "\u001b[34mEpoch 1/40 : |█████████████████-----------------------| 42.50% [51/120 01:06<01:30 0.2450]\u001b[0m\n",
      "\u001b[34mEpoch 1/40 : |█████████████████-----------------------| 43.33% [52/120 01:07<01:28 0.2450]\u001b[0m\n",
      "\u001b[34mEpoch 1/40 : |█████████████████-----------------------| 44.17% [53/120 01:09<01:27 0.2445]\u001b[0m\n",
      "\u001b[34mEpoch 1/40 : |██████████████████----------------------| 45.00% [54/120 01:10<01:25 0.2562]\u001b[0m\n",
      "\u001b[34mEpoch 1/40 : |██████████████████----------------------| 45.83% [55/120 01:11<01:24 0.2548]\u001b[0m\n",
      "\u001b[34mEpoch 1/40 : |██████████████████----------------------| 46.67% [56/120 01:12<01:23 0.2533]\u001b[0m\n",
      "\u001b[34mEpoch 1/40 : |███████████████████---------------------| 47.50% [57/120 01:13<01:21 0.2462]\u001b[0m\n",
      "\u001b[34mEpoch 1/40 : |███████████████████---------------------| 48.33% [58/120 01:15<01:20 0.2394]\u001b[0m\n",
      "\u001b[34mEpoch 1/40 : |███████████████████---------------------| 49.17% [59/120 01:16<01:18 0.2328]\u001b[0m\n",
      "\u001b[34mEpoch 1/40 : |████████████████████--------------------| 50.00% [60/120 01:17<01:17 0.2265]\u001b[0m\n",
      "\u001b[34mEpoch 1/40 : |████████████████████--------------------| 50.83% [61/120 01:18<01:16 0.2233]\u001b[0m\n",
      "\u001b[34mEpoch 1/40 : |████████████████████--------------------| 51.67% [62/120 01:19<01:14 0.2200]\u001b[0m\n",
      "\u001b[34mEpoch 1/40 : |█████████████████████-------------------| 52.50% [63/120 01:21<01:13 0.2141]\u001b[0m\n",
      "\u001b[34mEpoch 1/40 : |█████████████████████-------------------| 53.33% [64/120 01:22<01:12 0.2085]\u001b[0m\n",
      "\u001b[34mEpoch 1/40 : |█████████████████████-------------------| 54.17% [65/120 01:23<01:10 0.2051]\u001b[0m\n",
      "\u001b[34mEpoch 1/40 : |██████████████████████------------------| 55.00% [66/120 01:24<01:09 0.2017]\u001b[0m\n",
      "\u001b[34mEpoch 1/40 : |██████████████████████------------------| 55.83% [67/120 01:26<01:08 0.2022]\u001b[0m\n",
      "\u001b[34mEpoch 1/40 : |██████████████████████------------------| 56.67% [68/120 01:27<01:06 0.1985]\u001b[0m\n",
      "\u001b[34mEpoch 1/40 : |███████████████████████-----------------| 57.50% [69/120 01:28<01:05 0.2042]\u001b[0m\n",
      "\u001b[34mEpoch 1/40 : |███████████████████████-----------------| 58.33% [70/120 01:29<01:04 0.1991]\u001b[0m\n",
      "\u001b[34mEpoch 1/40 : |███████████████████████-----------------| 59.17% [71/120 01:30<01:02 0.2032]\u001b[0m\n",
      "\u001b[34mEpoch 1/40 : |████████████████████████----------------| 60.00% [72/120 01:32<01:01 0.1982]\u001b[0m\n",
      "\u001b[34mEpoch 1/40 : |████████████████████████----------------| 60.83% [73/120 01:33<01:00 0.2004]\u001b[0m\n",
      "\u001b[34mEpoch 1/40 : |████████████████████████----------------| 61.67% [74/120 01:34<00:58 0.2018]\u001b[0m\n",
      "\u001b[34mEpoch 1/40 : |█████████████████████████---------------| 62.50% [75/120 01:35<00:57 0.1979]\u001b[0m\n",
      "\u001b[34mEpoch 1/40 : |█████████████████████████---------------| 63.33% [76/120 01:36<00:56 0.1941]\u001b[0m\n",
      "\u001b[34mEpoch 1/40 : |█████████████████████████---------------| 64.17% [77/120 01:38<00:54 0.1896]\u001b[0m\n",
      "\u001b[34mEpoch 1/40 : |██████████████████████████--------------| 65.00% [78/120 01:39<00:53 0.1852]\u001b[0m\n",
      "\u001b[34mEpoch 1/40 : |██████████████████████████--------------| 65.83% [79/120 01:40<00:52 0.1852]\u001b[0m\n",
      "\u001b[34mEpoch 1/40 : |██████████████████████████--------------| 66.67% [80/120 01:41<00:50 0.1908]\u001b[0m\n",
      "\u001b[34mEpoch 1/40 : |███████████████████████████-------------| 67.50% [81/120 01:43<00:49 0.1903]\u001b[0m\n",
      "\u001b[34mEpoch 1/40 : |███████████████████████████-------------| 68.33% [82/120 01:44<00:48 0.1950]\u001b[0m\n",
      "\u001b[34mEpoch 1/40 : |███████████████████████████-------------| 69.17% [83/120 01:45<00:47 0.1915]\u001b[0m\n",
      "\u001b[34mEpoch 1/40 : |████████████████████████████------------| 70.00% [84/120 01:46<00:45 0.1953]\u001b[0m\n",
      "\u001b[34mEpoch 1/40 : |████████████████████████████------------| 70.83% [85/120 01:47<00:44 0.1978]\u001b[0m\n",
      "\u001b[34mEpoch 1/40 : |████████████████████████████------------| 71.67% [86/120 01:49<00:43 0.2003]\u001b[0m\n",
      "\u001b[34mEpoch 1/40 : |█████████████████████████████-----------| 72.50% [87/120 01:50<00:41 0.1982]\u001b[0m\n",
      "\u001b[34mEpoch 1/40 : |█████████████████████████████-----------| 73.33% [88/120 01:51<00:40 0.1977]\u001b[0m\n",
      "\u001b[34mEpoch 1/40 : |█████████████████████████████-----------| 74.17% [89/120 01:52<00:39 0.2055]\u001b[0m\n",
      "\u001b[34mEpoch 1/40 : |██████████████████████████████----------| 75.00% [90/120 01:54<00:38 0.2060]\u001b[0m\n",
      "\u001b[34mEpoch 1/40 : |██████████████████████████████----------| 75.83% [91/120 01:55<00:36 0.2066]\u001b[0m\n",
      "\u001b[34mEpoch 1/40 : |██████████████████████████████----------| 76.67% [92/120 01:56<00:35 0.2034]\u001b[0m\n",
      "\u001b[34mEpoch 1/40 : |███████████████████████████████---------| 77.50% [93/120 01:57<00:34 0.2036]\u001b[0m\n",
      "\u001b[34mEpoch 1/40 : |███████████████████████████████---------| 78.33% [94/120 01:58<00:32 0.2036]\u001b[0m\n",
      "\u001b[34mEpoch 1/40 : |███████████████████████████████---------| 79.17% [95/120 02:00<00:31 0.2010]\u001b[0m\n",
      "\u001b[34mEpoch 1/40 : |████████████████████████████████--------| 80.00% [96/120 02:01<00:30 0.1982]\u001b[0m\n",
      "\u001b[34mEpoch 1/40 : |████████████████████████████████--------| 80.83% [97/120 02:02<00:29 0.1975]\u001b[0m\n",
      "\u001b[34mEpoch 1/40 : |████████████████████████████████--------| 81.67% [98/120 02:03<00:27 0.1943]\u001b[0m\n",
      "\u001b[34mEpoch 1/40 : |█████████████████████████████████-------| 82.50% [99/120 02:04<00:26 0.1908]\u001b[0m\n",
      "\u001b[34mEpoch 1/40 : |█████████████████████████████████-------| 83.33% [100/120 02:06<00:25 0.1879]\u001b[0m\n",
      "\u001b[34mEpoch 1/40 : |█████████████████████████████████-------| 84.17% [101/120 02:07<00:23 0.1844]\u001b[0m\n",
      "\u001b[34mEpoch 1/40 : |██████████████████████████████████------| 85.00% [102/120 02:08<00:22 0.1815]\u001b[0m\n",
      "\u001b[34mEpoch 1/40 : |██████████████████████████████████------| 85.83% [103/120 02:09<00:21 0.1804]\u001b[0m\n",
      "\u001b[34mEpoch 1/40 : |██████████████████████████████████------| 86.67% [104/120 02:10<00:20 0.1776]\u001b[0m\n",
      "\u001b[34mEpoch 1/40 : |███████████████████████████████████-----| 87.50% [105/120 02:12<00:18 0.1746]\u001b[0m\n",
      "\u001b[34mEpoch 1/40 : |███████████████████████████████████-----| 88.33% [106/120 02:13<00:17 0.1833]\u001b[0m\n",
      "\u001b[34mEpoch 1/40 : |███████████████████████████████████-----| 89.17% [107/120 02:14<00:16 0.1797]\u001b[0m\n",
      "\u001b[34mEpoch 1/40 : |████████████████████████████████████----| 90.00% [108/120 02:15<00:15 0.1768]\u001b[0m\n",
      "\u001b[34mEpoch 1/40 : |████████████████████████████████████----| 90.83% [109/120 02:17<00:13 0.1761]\u001b[0m\n",
      "\u001b[34mEpoch 1/40 : |████████████████████████████████████----| 91.67% [110/120 02:18<00:12 0.1755]\u001b[0m\n",
      "\u001b[34mEpoch 1/40 : |█████████████████████████████████████---| 92.50% [111/120 02:19<00:11 0.1723]\u001b[0m\n",
      "\u001b[34mEpoch 1/40 : |█████████████████████████████████████---| 93.33% [112/120 02:20<00:10 0.1698]\u001b[0m\n",
      "\u001b[34mEpoch 1/40 : |█████████████████████████████████████---| 94.17% [113/120 02:21<00:08 0.1663]\u001b[0m\n",
      "\u001b[34mEpoch 1/40 : |██████████████████████████████████████--| 95.00% [114/120 02:23<00:07 0.1637]\u001b[0m\n",
      "\u001b[34mEpoch 1/40 : |██████████████████████████████████████--| 95.83% [115/120 02:24<00:06 0.1612]\u001b[0m\n",
      "\u001b[34mEpoch 1/40 : |██████████████████████████████████████--| 96.67% [116/120 02:25<00:05 0.1584]\u001b[0m\n",
      "\u001b[34mEpoch 1/40 : |███████████████████████████████████████-| 97.50% [117/120 02:26<00:03 0.1573]\u001b[0m\n",
      "\u001b[34mEpoch 1/40 : |███████████████████████████████████████-| 98.33% [118/120 02:27<00:02 0.1546]\u001b[0m\n",
      "\u001b[34mEpoch 1/40 : |███████████████████████████████████████-| 99.17% [119/120 02:29<00:01 0.1518]\u001b[0m\n",
      "\u001b[34mEpoch 1/40 : |████████████████████████████████████████| 100.00% [120/120 02:30<00:00 0.1493]#015#015Epoch 1/40 :\u001b[0m\n",
      "\u001b[34mEpoch 1/40 :\u001b[0m\n",
      "\u001b[34m█\u001b[0m\n",
      "\u001b[34mEpoch 1/40 : |----------------------------------------| 0.00% [0/30 00:00<?]\u001b[0m\n",
      "\u001b[34mEpoch 1/40 : |█---------------------------------------| 3.33% [1/30 00:00<00:28]\u001b[0m\n",
      "\u001b[34mEpoch 1/40 : |██--------------------------------------| 6.67% [2/30 00:01<00:21 0.1466]\u001b[0m\n",
      "\u001b[34mEpoch 1/40 : |████------------------------------------| 10.00% [3/30 00:02<00:19 0.1466]\u001b[0m\n",
      "\u001b[34mEpoch 1/40 : |█████-----------------------------------| 13.33% [4/30 00:02<00:18 0.1466]\u001b[0m\n",
      "\u001b[34mEpoch 1/40 : |██████----------------------------------| 16.67% [5/30 00:03<00:17 0.1466]\u001b[0m\n",
      "\u001b[34mEpoch 1/40 : |████████--------------------------------| 20.00% [6/30 00:04<00:16 0.1466]\u001b[0m\n",
      "\u001b[34mEpoch 1/40 : |█████████-------------------------------| 23.33% [7/30 00:04<00:15 0.1466]\u001b[0m\n",
      "\u001b[34mEpoch 1/40 : |██████████------------------------------| 26.67% [8/30 00:05<00:14 0.1466]\u001b[0m\n",
      "\u001b[34mEpoch 1/40 : |████████████----------------------------| 30.00% [9/30 00:05<00:13 0.1466]\u001b[0m\n",
      "\u001b[34mEpoch 1/40 : |█████████████---------------------------| 33.33% [10/30 00:06<00:12 0.1466]\u001b[0m\n",
      "\u001b[34mEpoch 1/40 : |██████████████--------------------------| 36.67% [11/30 00:07<00:12 0.1466]\u001b[0m\n",
      "\u001b[34mEpoch 1/40 : |████████████████------------------------| 40.00% [12/30 00:07<00:11 0.1466]\u001b[0m\n",
      "\u001b[34mEpoch 1/40 : |█████████████████-----------------------| 43.33% [13/30 00:08<00:10 0.1466]\u001b[0m\n",
      "\u001b[34mEpoch 1/40 : |██████████████████----------------------| 46.67% [14/30 00:08<00:10 0.1466]\u001b[0m\n",
      "\u001b[34mEpoch 1/40 : |████████████████████--------------------| 50.00% [15/30 00:09<00:09 0.1466]\u001b[0m\n",
      "\u001b[34mEpoch 1/40 : |█████████████████████-------------------| 53.33% [16/30 00:10<00:08 0.1466]\u001b[0m\n",
      "\u001b[34mEpoch 1/40 : |██████████████████████------------------| 56.67% [17/30 00:10<00:08 0.1466]\u001b[0m\n",
      "\u001b[34mEpoch 1/40 : |████████████████████████----------------| 60.00% [18/30 00:11<00:07 0.1466]\u001b[0m\n",
      "\u001b[34mEpoch 1/40 : |█████████████████████████---------------| 63.33% [19/30 00:11<00:06 0.1466]\u001b[0m\n",
      "\u001b[34mEpoch 1/40 : |██████████████████████████--------------| 66.67% [20/30 00:12<00:06 0.1466]\u001b[0m\n",
      "\u001b[34mEpoch 1/40 : |████████████████████████████------------| 70.00% [21/30 00:13<00:05 0.1466]\u001b[0m\n",
      "\u001b[34mEpoch 1/40 : |█████████████████████████████-----------| 73.33% [22/30 00:13<00:04 0.1466]\u001b[0m\n",
      "\u001b[34mEpoch 1/40 : |██████████████████████████████----------| 76.67% [23/30 00:14<00:04 0.1466]\u001b[0m\n",
      "\u001b[34mEpoch 1/40 : |████████████████████████████████--------| 80.00% [24/30 00:14<00:03 0.1466]\u001b[0m\n",
      "\u001b[34mEpoch 1/40 : |█████████████████████████████████-------| 83.33% [25/30 00:15<00:03 0.1466]\u001b[0m\n",
      "\u001b[34mEpoch 1/40 : |██████████████████████████████████------| 86.67% [26/30 00:16<00:02 0.1466]\u001b[0m\n",
      "\u001b[34mEpoch 1/40 : |████████████████████████████████████----| 90.00% [27/30 00:16<00:01 0.1466]\u001b[0m\n",
      "\u001b[34mEpoch 1/40 : |█████████████████████████████████████---| 93.33% [28/30 00:17<00:01 0.1466]\u001b[0m\n",
      "\u001b[34mEpoch 1/40 : |██████████████████████████████████████--| 96.67% [29/30 00:17<00:00 0.1466]\u001b[0m\n",
      "\u001b[34mEpoch 1/40 : |████████████████████████████████████████| 100.00% [30/30 00:18<00:00 0.1466]#015#015Epoch 1/40 :\u001b[0m\n",
      "\u001b[34mTraceback (most recent call last):\n",
      "  File \"train.py\", line 110, in <module>\u001b[0m\n",
      "\u001b[34mdo_learning(\"/tmp/\", paths.TRAINING_OUTPUT_DIR_SAGEMAKER)\n",
      "  File \"train.py\", line 95, in do_learning\n",
      "    train(learn, config)\n",
      "  File \"train.py\", line 74, in train\u001b[0m\n",
      "\u001b[34mlearn.fit(config[\"epochs\"],\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/fastai/learner.py\", line 256, in fit\u001b[0m\n",
      "\u001b[34mself._with_events(self._do_fit, 'fit', CancelFitException, self._end_cleanup)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/fastai/learner.py\", line 193, in _with_events\n",
      "    try: self(f'before_{event_type}');  f()\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/fastai/learner.py\", line 245, in _do_fit\n",
      "    self._with_events(self._do_epoch, 'epoch', CancelEpochException)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/fastai/learner.py\", line 193, in _with_events\n",
      "    try: self(f'before_{event_type}');  f()\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/fastai/learner.py\", line 240, in _do_epoch\n",
      "    self._do_epoch_validate()\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/fastai/learner.py\", line 236, in _do_epoch_validate\n",
      "    with torch.no_grad(): self._with_events(self.all_batches, 'validate', CancelValidException)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/fastai/learner.py\", line 195, in _with_events\u001b[0m\n",
      "\u001b[34mself(f'after_{event_type}');  final()\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/fastai/learner.py\", line 171, in __call__\u001b[0m\n",
      "\u001b[34mdef __call__(self, event_name): L(event_name).map(self._call_one)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/fastcore/foundation.py\", line 156, in map\n",
      "    def map(self, f, *args, **kwargs): return self._new(map_ex(self, f, *args, gen=False, **kwargs))\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/fastcore/basics.py\", line 840, in map_ex\n",
      "    return list(res)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/fastcore/basics.py\", line 825, in __call__\n",
      "    return self.func(*fargs, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/fastai/learner.py\", line 175, in _call_one\n",
      "    for cb in self.cbs.sorted('order'): cb(event_name)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/fastai/callback/core.py\", line 62, in __call__\n",
      "    except Exception as e: raise modify_exception(e, f'Exception occured in `{self.__class__.__name__}` when calling event `{event_name}`:\\n\\t{e.args[0]}', replace=True)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/fastai/callback/core.py\", line 60, in __call__\n",
      "    try: res = getcallable(self, event_name)()\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/fastai/learner.py\", line 566, in after_validate\u001b[0m\n",
      "\u001b[34mdef after_validate(self): self.log += self._valid_mets.map(_maybe_item)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/fastcore/foundation.py\", line 156, in map\n",
      "    def map(self, f, *args, **kwargs): return self._new(map_ex(self, f, *args, gen=False, **kwargs))\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/fastcore/basics.py\", line 840, in map_ex\u001b[0m\n",
      "\u001b[34mreturn list(res)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/fastcore/basics.py\", line 825, in __call__\u001b[0m\n",
      "\u001b[34mreturn self.func(*fargs, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/fastai/learner.py\", line 520, in _maybe_item\u001b[0m\n",
      "\u001b[34mt = t.value\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/fastai/metrics.py\", line 70, in value\u001b[0m\n",
      "\u001b[34mreturn self.func(targs, preds, **self.kwargs) if self.invert_args else self.func(preds, targs, **self.kwargs)\n",
      "  File \"/opt/ml/code/metrics.py\", line 29, in roc_probseverecovid\u001b[0m\n",
      "\u001b[34mreturn roc_auc_score(labels, preds)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/sklearn/metrics/_ranking.py\", line 572, in roc_auc_score\u001b[0m\n",
      "\u001b[34mreturn _average_binary_score(\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/sklearn/metrics/_base.py\", line 75, in _average_binary_score\n",
      "    return binary_metric(y_true, y_score, sample_weight=sample_weight)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/sklearn/metrics/_ranking.py\", line 339, in _binary_roc_auc_score\u001b[0m\n",
      "\u001b[34mraise ValueError(\u001b[0m\n",
      "\u001b[34mValueError: Exception occured in `Recorder` when calling event `after_validate`:\u001b[0m\n",
      "\u001b[34m#011Only one class present in y_true. ROC AUC score is not defined in that case.\u001b[0m\n",
      "\u001b[34m2023-02-02 13:06:38,186 sagemaker-training-toolkit INFO     Waiting for the process to finish and give a return code.\u001b[0m\n",
      "\u001b[34m2023-02-02 13:06:38,187 sagemaker-training-toolkit INFO     Done waiting for a return code. Received 1 from exiting process.\u001b[0m\n",
      "\u001b[34m2023-02-02 13:06:38,187 sagemaker-training-toolkit ERROR    Reporting training FAILURE\u001b[0m\n",
      "\u001b[34m2023-02-02 13:06:38,187 sagemaker-training-toolkit ERROR    ExecuteUserScriptError:\u001b[0m\n",
      "\u001b[34mExitCode 1\u001b[0m\n",
      "\u001b[34mErrorMessage \"self._with_events(self._do_fit, 'fit', CancelFitException, self._end_cleanup)\n",
      " File \"/opt/conda/lib/python3.8/site-packages/fastai/learner.py\", line 193, in _with_events\n",
      " try: self(f'before_{event_type}');  f()\n",
      " File \"/opt/conda/lib/python3.8/site-packages/fastai/learner.py\", line 245, in _do_fit\n",
      " self._with_events(self._do_epoch, 'epoch', CancelEpochException)\n",
      " File \"/opt/conda/lib/python3.8/site-packages/fastai/learner.py\", line 240, in _do_epoch\n",
      " self._do_epoch_validate()\n",
      " File \"/opt/conda/lib/python3.8/site-packages/fastai/learner.py\", line 236, in _do_epoch_validate\n",
      " with torch.no_grad(): self._with_events(self.all_batches, 'validate', CancelValidException)\n",
      " File \"/opt/conda/lib/python3.8/site-packages/fastai/learner.py\", line 195, in _with_events\n",
      " self(f'after_{event_type}');  final()\n",
      " File \"/opt/conda/lib/python3.8/site-packages/fastai/learner.py\", line 171, in __call__\n",
      " def __call__(self, event_name): L(event_name).map(self._call_one)\n",
      " File \"/opt/conda/lib/python3.8/site-packages/fastcore/foundation.py\", line 156, in map\n",
      " def map(self, f, *args, **kwargs): return self._new(map_ex(self, f, *args, gen=False, **kwargs))\n",
      " File \"/opt/conda/lib/python3.8/site-packages/fastcore/basics.py\", line 840, in map_ex\n",
      " return list(res)\n",
      " File \"/opt/conda/lib/python3.8/site-packages/fastcore/basics.py\", line 825, in __call__\n",
      " return self.func(*fargs, **kwargs)\n",
      " File \"/opt/conda/lib/python3.8/site-packages/fastai/learner.py\", line 175, in _call_one\n",
      " for cb in self.cbs.sorted('order'): cb(event_name)\n",
      " File \"/opt/conda/lib/python3.8/site-packages/fastai/callback/core.py\", line 62, in __call__\n",
      " except Exception as e: raise modify_exception(e, f'Exception occured in `{self.__class__.__name__}` when calling event `{event_name}`:\\n\\t{e.args[0]}', replace=True)\n",
      " File \"/opt/conda/lib/python3.8/site-packages/fastai/callback/core.py\", line 60, in __call__\n",
      " try: res = getcallable(self, event_name)()\n",
      " File \"/opt/conda/lib/python3.8/site-packages/fastai/learner.py\", line 566, in after_validate\n",
      " def after_validate(self): self.log += self._valid_mets.map(_maybe_item)\n",
      " File \"/opt/conda/lib/python3.8/site-packages/fastai/learner.py\", line 520, in _maybe_item\n",
      " t = t.value\n",
      " File \"/opt/conda/lib/python3.8/site-packages/fastai/metrics.py\", line 70, in value\n",
      " return self.func(targs, preds, **self.kwargs) if self.invert_args else self.func(preds, targs, **self.kwargs)\n",
      " File \"/opt/ml/code/metrics.py\", line 29, in roc_probseverecovid\n",
      " return roc_auc_score(labels, preds)\n",
      " File \"/opt/conda/lib/python3.8/site-packages/sklearn/metrics/_ranking.py\", line 572, in roc_auc_score\n",
      " return _average_binary_score(\n",
      " File \"/opt/conda/lib/python3.8/site-packages/sklearn/metrics/_base.py\", line 75, in _average_binary_score\n",
      " return binary_metric(y_true, y_score, sample_weight=sample_weight)\n",
      " File \"/opt/conda/lib/python3.8/site-packages/sklearn/metrics/_ranking.py\", line 339, in _binary_roc_auc_score\n",
      " raise ValueError(\n",
      " ValueError: Exception occured in `Recorder` when calling event `after_validate`\n",
      " #011Only one class present in y_true. ROC AUC score is not defined in that case.\"\u001b[0m\n",
      "\u001b[34mCommand \"/opt/conda/bin/python3.8 train.py\"\u001b[0m\n",
      "\u001b[34m2023-02-02 13:06:38,187 sagemaker-training-toolkit ERROR    Encountered exit_code 1\u001b[0m\n",
      "\n",
      "2023-02-02 13:06:52 Uploading - Uploading generated training model\n",
      "2023-02-02 13:06:52 Failed - Training job failed\n"
     ]
    },
    {
     "ename": "UnexpectedStatusException",
     "evalue": "Error for Training job pytorch-training-2023-02-02-12-58-09-332: Failed. Reason: AlgorithmError: ExecuteUserScriptError:\nExitCode 1\nErrorMessage \"self._with_events(self._do_fit, 'fit', CancelFitException, self._end_cleanup)\n File \"/opt/conda/lib/python3.8/site-packages/fastai/learner.py\", line 193, in _with_events\n try: self(f'before_{event_type}');  f()\n File \"/opt/conda/lib/python3.8/site-packages/fastai/learner.py\", line 245, in _do_fit\n self._with_events(self._do_epoch, 'epoch', CancelEpochException)\n File \"/opt/conda/lib/python3.8/site-packages/fastai/learner.py\", line 240, in _do_epoch\n self._do_epoch_validate()\n File \"/opt/conda/lib/python3.8/site-packages/fastai/learner.py\", line 236, in _do_epoch_validate\n with torch.no_grad(): self._with_events(self.all_batches, 'validate', CancelValidException)\n File \"/opt/conda/lib/python3.8/site-packages/fastai/learner.py\", line 195, in _with_events\n self(f'after_{event_type}');  final()\n File \"/opt/conda/lib/python3.8/site-packages/fastai/learner.py\", line 171, in __call__\n def __call__(self, event_name): L(event_name).map(self._call_one)\n F",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnexpectedStatusException\u001b[0m                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-616fb6ff67f3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m estimator.fit(\n\u001b[1;32m     18\u001b[0m     inputs={  # Each input folder passed must have contents. \n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0;34m'preprocessed'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpreprocessed_location\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m     }  # Paths are available on the training instance in environment variables named SM_CHANNEL_<KEY>, e.g. SM_CHANNEL_IMAGES\n\u001b[1;32m     21\u001b[0m )\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sagemaker/workflow/pipeline_context.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    270\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0m_StepArguments\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretrieve_caller_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself_instance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 272\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mrun_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    273\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sagemaker/estimator.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, inputs, wait, logs, job_name, experiment_config)\u001b[0m\n\u001b[1;32m   1126\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlatest_training_job\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1127\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1128\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlatest_training_job\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_compilation_job_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sagemaker/estimator.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, logs)\u001b[0m\n\u001b[1;32m   2240\u001b[0m         \u001b[0;31m# If logs are requested, call logs_for_jobs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2241\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlogs\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"None\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2242\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogs_for_job\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjob_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2243\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2244\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait_for_job\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjob_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sagemaker/session.py\u001b[0m in \u001b[0;36mlogs_for_job\u001b[0;34m(self, job_name, wait, poll, log_type)\u001b[0m\n\u001b[1;32m   4070\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4071\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4072\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_job_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdescription\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"TrainingJobStatus\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4073\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdot\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4074\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sagemaker/session.py\u001b[0m in \u001b[0;36m_check_job_status\u001b[0;34m(self, job, desc, status_key_name)\u001b[0m\n\u001b[1;32m   3604\u001b[0m                 \u001b[0mmessage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3605\u001b[0m                 \u001b[0mallowed_statuses\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Completed\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Stopped\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3606\u001b[0;31m                 \u001b[0mactual_status\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3607\u001b[0m             )\n\u001b[1;32m   3608\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnexpectedStatusException\u001b[0m: Error for Training job pytorch-training-2023-02-02-12-58-09-332: Failed. Reason: AlgorithmError: ExecuteUserScriptError:\nExitCode 1\nErrorMessage \"self._with_events(self._do_fit, 'fit', CancelFitException, self._end_cleanup)\n File \"/opt/conda/lib/python3.8/site-packages/fastai/learner.py\", line 193, in _with_events\n try: self(f'before_{event_type}');  f()\n File \"/opt/conda/lib/python3.8/site-packages/fastai/learner.py\", line 245, in _do_fit\n self._with_events(self._do_epoch, 'epoch', CancelEpochException)\n File \"/opt/conda/lib/python3.8/site-packages/fastai/learner.py\", line 240, in _do_epoch\n self._do_epoch_validate()\n File \"/opt/conda/lib/python3.8/site-packages/fastai/learner.py\", line 236, in _do_epoch_validate\n with torch.no_grad(): self._with_events(self.all_batches, 'validate', CancelValidException)\n File \"/opt/conda/lib/python3.8/site-packages/fastai/learner.py\", line 195, in _with_events\n self(f'after_{event_type}');  final()\n File \"/opt/conda/lib/python3.8/site-packages/fastai/learner.py\", line 171, in __call__\n def __call__(self, event_name): L(event_name).map(self._call_one)\n F"
     ]
    }
   ],
   "source": [
    "# Do Training\n",
    "\n",
    "estimator = PyTorch(\n",
    "    entry_point='train.py',  # A python file in source_dir\n",
    "    source_dir=os.getcwd(),  # local path (in SageMaker Studio)\n",
    "    role=get_execution_role(),\n",
    "    instance_type='ml.g4dn.xlarge',\n",
    "    instance_count=1,\n",
    "    volume_size=5,  # Scratch volume mounted at /tmp/ in GB\n",
    "    framework_version='1.12',\n",
    "    py_version='py38',\n",
    "    max_run=600,  # in seconds, maximum is 5 days\n",
    "    checkpoint_s3_uri=artifact_location,  # gets pulled from to checkpoint_local_path at the start of training, and pushed to at the end\n",
    "    checkpoint_local_path= '/artifact/',  \n",
    ")\n",
    "\n",
    "estimator.fit(\n",
    "    inputs={  # Each input folder passed must have contents. \n",
    "        'preprocessed': preprocessed_location,\n",
    "    }  # Paths are available on the training instance in environment variables named SM_CHANNEL_<KEY>, e.g. SM_CHANNEL_IMAGES\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cf1aa44-b655-444b-96c0-951408cc9935",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
